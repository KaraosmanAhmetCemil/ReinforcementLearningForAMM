# ReinforcementLearningForAMM

Dieses Repository enthÃ¤lt die Implementierungen von **Reinforcement-Learning-Frameworks** zur Optimierung von **Automated Market Makers (AMMs)** auf Basis von **Uniswap V3 und V4**.  

Im Fokus stehen zwei Algorithmen:
- **Dueling Double Deep Q-Network (DDQN)**
- **Proximal Policy Optimization (PPO)**

Beide AnsÃ¤tze wurden in einer simulierten Umgebung evaluiert, um **Slippage**, **Divergence Loss**, **Liquidity Utilization** und **Rewards** zu analysieren.  

---

## ğŸ“‚ Struktur des Repositories
- `DDQN/` â€“ Implementierung des Dueling DDQN-Frameworks fÃ¼r Uniswap V3 und V4  
- `PPO/` â€“ Implementierung des PPO-Frameworks fÃ¼r Uniswap V3 und V4  
- `graphs/` â€“ Visualisierungen der Trainingsergebnisse (Reward-VerlÃ¤ufe, Slippage, Divergence Loss etc.)  

---

## ğŸ“Š Datengrundlage
FÃ¼r Training und Evaluation wurde der folgende Datensatz mit **ETH/USDT 1-Stunden-Klines** verwendet:  
ğŸ‘‰ [Ethereum Historical Dataset (Kaggle)](https://www.kaggle.com/datasets/prasoonkottarathil/ethereum-historical-dataset)

Die Daten wurden preprocessiert und als Input fÃ¼r **LSTM-Preisprognosen** sowie fÃ¼r die **RL-Agenten** genutzt.  

---

## âš™ï¸ Anforderungen
- Python 3.10+  
- PyTorch / PyTorch Lightning  
- NumPy, Pandas, Matplotlib  
- Gymnasium (oder OpenAI Gym)  

---

## ğŸš€ AusfÃ¼hrung
1. Repository klonen:
   ```bash
   git clone https://github.com/KaraosmanAhmetCemil/ReinforcementLearningForAMM.git
   cd ReinforcementLearningForAMM
